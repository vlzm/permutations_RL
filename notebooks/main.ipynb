{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from src.app import PermutationSolver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "config = {\n",
    "                'n_permutations_length': n,\n",
    "                \n",
    "                # Random walks params\n",
    "                'random_walks_type': 'non-backtracking-beam',\n",
    "                'n_random_walk_length': int(n * (n-1) / 2),\n",
    "                'n_random_walks_to_generate': 1000,\n",
    "                'n_random_walks_steps_back_to_ban': 8,\n",
    "                \n",
    "                # Neural Net params\n",
    "                'model_type': 'MLP',\n",
    "                'list_layers_sizes': [4096],\n",
    "                'n_epochs': 100,\n",
    "                'batch_size': 1024,\n",
    "                'lr_supervised': 1e-3,\n",
    "                \n",
    "                # DQN training\n",
    "                'n_epochs_dqn': 5000,\n",
    "                'flag_dqn_round': False,\n",
    "                'n_random_walks_to_generate_dqn': 1000,\n",
    "                'verbose_loc': 50,\n",
    "                'lr_rl': 1e-3,\n",
    "                \n",
    "                # Beam search\n",
    "                'beam_search_torch': True,\n",
    "                'beam_search_Fironov': False,\n",
    "                'beam_width': 1,\n",
    "                'n_steps_limit': 4 * n**2,\n",
    "                'alpha_previous_cost_accumulation': 0,\n",
    "                'beam_search_models_or_heuristics': 'model_torch',\n",
    "                'ban_p0_p1_transposition_if_p0_lt_p1_ie_already_sorted': False,\n",
    "                'n_beam_search_steps_back_to_ban': 32,\n",
    "                \n",
    "                # What to solve\n",
    "                'solve_random_or_longest_state': 'solve_LRX_longest',\n",
    "                'verbose': 100\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "362880\n",
      "X.shape: torch.Size([362880, 9])\n",
      "y.shape: torch.Size([362880])\n",
      "Training MLP with random walks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP with random walks: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s, loss=10.0646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362880\n",
      "X.shape: torch.Size([362880, 9])\n",
      "y.shape: torch.Size([362880])\n",
      "Training DQN with random walks\n",
      "Starting DQN training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP with random walks: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s, loss=1.2825, hinge: 1.2494, anchor: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 9.1s\n",
      "{'n_permutations_length': 9, 'random_walks_type': 'non-backtracking-beam', 'n_random_walk_length': 36, 'n_random_walks_to_generate': 10000, 'n_random_walks_steps_back_to_ban': 8, 'model_type': 'MLP', 'list_layers_sizes': [4096], 'n_epochs': 10, 'batch_size': 1024, 'lr_supervised': 0.001, 'n_epochs_dqn': 10, 'flag_dqn_round': False, 'n_random_walks_to_generate_dqn': 10000, 'verbose_loc': 50, 'lr_rl': 0.001, 'beam_search_torch': True, 'beam_search_Fironov': False, 'beam_width': 1, 'n_steps_limit': 40000, 'alpha_previous_cost_accumulation': 0, 'beam_search_models_or_heuristics': 'model_torch', 'ban_p0_p1_transposition_if_p0_lt_p1_ie_already_sorted': False, 'n_beam_search_steps_back_to_ban': 32, 'solve_random_or_longest_state': 'solve_LRX_longest', 'verbose': 100, 'mode': 'single_hard_hinge', 'w_hinge': 1.0, 'w_anchor': 0}\n",
      "\n",
      "beam_width: 1\n",
      "n= 9\n",
      "n(n-1)/2= 36\n",
      "Found Path Length: 36 flag_found_destination: True\n",
      "4096\n",
      "1000001\n",
      "X.shape: torch.Size([1000001, 10])\n",
      "y.shape: torch.Size([1000001])\n",
      "Training MLP with random walks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP with random walks: 100%|██████████| 10/10 [00:07<00:00,  1.30it/s, loss=24.5193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000001\n",
      "X.shape: torch.Size([1000001, 10])\n",
      "y.shape: torch.Size([1000001])\n",
      "Training DQN with random walks\n",
      "Starting DQN training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP with random walks: 100%|██████████| 10/10 [00:11<00:00,  1.20s/it, loss=4.1453, hinge: 3.7065, anchor: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 12.0s\n",
      "{'n_permutations_length': 10, 'random_walks_type': 'non-backtracking-beam', 'n_random_walk_length': 45, 'n_random_walks_to_generate': 10000, 'n_random_walks_steps_back_to_ban': 8, 'model_type': 'MLP', 'list_layers_sizes': [4096], 'n_epochs': 10, 'batch_size': 1024, 'lr_supervised': 0.001, 'n_epochs_dqn': 10, 'flag_dqn_round': False, 'n_random_walks_to_generate_dqn': 10000, 'verbose_loc': 50, 'lr_rl': 0.001, 'beam_search_torch': True, 'beam_search_Fironov': False, 'beam_width': 1, 'n_steps_limit': 40000, 'alpha_previous_cost_accumulation': 0, 'beam_search_models_or_heuristics': 'model_torch', 'ban_p0_p1_transposition_if_p0_lt_p1_ie_already_sorted': False, 'n_beam_search_steps_back_to_ban': 32, 'solve_random_or_longest_state': 'solve_LRX_longest', 'verbose': 100, 'mode': 'single_hard_hinge', 'w_hinge': 1.0, 'w_anchor': 0}\n",
      "\n",
      "beam_width: 1\n",
      "n= 10\n",
      "n(n-1)/2= 45\n",
      "Found Path Length: 55 flag_found_destination: True\n"
     ]
    }
   ],
   "source": [
    "n_perm_list = [9, 10]\n",
    "n_epoch_list = [10]\n",
    "n_epoch_dqn_list = [10]\n",
    "batch_size_list = [2**10]\n",
    "lr_supervised_list = [1e-3]\n",
    "lr_rl_list = [1e-3]\n",
    "n_rnd_walks_sup = [10_000]\n",
    "n_rnd_walks_rl = [10_000]\n",
    "anchor_list = [0]\n",
    "beam_width_list = [2**0]\n",
    "list_layers_sizes = [2**12]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for n_permutations_length in n_perm_list:\n",
    "\n",
    "    n = n_permutations_length\n",
    "    config['n_permutations_length'] = n\n",
    "    config['n_random_walk_length'] = int(n * (n-1) / 2)\n",
    "    \n",
    "    config['mode'] = 'single_hard_hinge'\n",
    "    config['w_hinge'] = 1.0\n",
    "    \n",
    "    for anchor_mode in anchor_list:\n",
    "        config['w_anchor'] = anchor_mode\n",
    "        for n_rnd_walks_sup_mode in n_rnd_walks_sup:\n",
    "            config['n_random_walks_to_generate'] = n_rnd_walks_sup_mode\n",
    "            for n_rnd_walks_rl_mode in n_rnd_walks_rl:\n",
    "                config['n_random_walks_to_generate_dqn'] = n_rnd_walks_rl_mode\n",
    "                solver = PermutationSolver(config)\n",
    "                solver.config['n_permutations_length'] = n_permutations_length\n",
    "                for list_layers_size in list_layers_sizes:\n",
    "                    solver.config['list_layers_sizes'] = [list_layers_size]\n",
    "                    print(list_layers_size)\n",
    "                    for lr in lr_supervised_list:\n",
    "                        solver.config['lr_supervised'] = lr\n",
    "                        for lr_rl in lr_rl_list:\n",
    "                            solver.config['lr_rl'] = lr_rl\n",
    "                            for batch_size in batch_size_list:\n",
    "                                solver.config['batch_size'] = batch_size\n",
    "                                for n_epoch in n_epoch_list:\n",
    "                                    solver.config['n_epochs'] = n_epoch\n",
    "                                    mlp_losses = solver.train_mlp(mode = config['w_anchor'])\n",
    "                                    # save mlp_model\n",
    "                                    torch.save(solver.mlp_model.state_dict(), f'models/mlp_model_{n_permutations_length}_{n_epoch}_{list_layers_size}_{lr}_{batch_size}.pth')\n",
    "                                    for n_epoch_dqn in n_epoch_dqn_list:\n",
    "                                        solver.config['n_epochs_dqn'] = n_epoch_dqn\n",
    "                                        dqn_losses = solver.train_dqn()\n",
    "                                        # save dqn_model\n",
    "                                        torch.save(solver.dqn_model.state_dict(), f'models/dqn_model_{n_permutations_length}_{n_epoch_dqn}_{list_layers_size}_{lr}_{batch_size}.pth')\n",
    "                                        for beam_width in beam_width_list:\n",
    "                                            solver.config['beam_width'] = beam_width\n",
    "                                            i_step, flag_found_destination, path = solver.test_beam_search()\n",
    "            \n",
    "                                            # calculate min and max of difference between solver.y_anchor and y_valid\n",
    "                                            # y_valid = solver.dqn_model(solver.X_anchor)\n",
    "                                            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                                            solver.dqn_trainer.model.eval()               # set to eval mode\n",
    "                                            y_parts = []\n",
    "                                            n_samples = len(solver.X_anchor)\n",
    "                                            with torch.no_grad():                 # <— no grad tracking\n",
    "                                                for start in range(0, n_samples, batch_size):\n",
    "                                                    end = start + batch_size\n",
    "                                                    X_batch = solver.X_anchor[start:end].to(device)\n",
    "                                                    y_batch = solver.dqn_trainer.model(X_batch)\n",
    "                                                    y_parts.append(y_batch.cpu()) # move back to CPU\n",
    "                                                    # explicitly free GPU memory\n",
    "                                                    del X_batch, y_batch\n",
    "                                                    torch.cuda.empty_cache()\n",
    "                                            \n",
    "                                            y_valid = torch.cat(y_parts, dim=0)\n",
    "                                            \n",
    "                                            diff = solver.y_anchor.cpu().detach().numpy() - y_valid.cpu().detach().numpy().reshape(1, -1)[0]\n",
    "                                            min_diff = diff.min()\n",
    "                                            max_diff = diff.max()\n",
    "                                            std_diff = diff.std()\n",
    "                                            mean_diff = diff.mean()\n",
    "                                            num_elements_less_than_minus_05 = (diff < -0.5).sum()\n",
    "                                            num_elements_larger_than_05 = (diff > 0.5).sum()\n",
    "                                            wrong_predictions = num_elements_less_than_minus_05 + num_elements_larger_than_05\n",
    "                                            percentage_wrong_predictions = wrong_predictions / len(diff)\n",
    "            \n",
    "                                            # save summary_df\n",
    "                                            summary_df_cur = pd.DataFrame({'n_permutations_length': n_permutations_length,\n",
    "                                                                           'n_rnd_walks_sup_mode': n_rnd_walks_sup_mode,\n",
    "                                                                           'n_rnd_walks_rl_mode': n_rnd_walks_rl_mode,\n",
    "                                                                           'anchor':anchor_mode,\n",
    "                                                                           'batch_size':batch_size,\n",
    "                                                                           'list_layers_sizes': [list_layers_size], \n",
    "                                                                           'lr_supervised': lr,\n",
    "                                                                           'lr_rl': lr_rl, \n",
    "                                                                           'n_epoch': n_epoch, \n",
    "                                                                           'n_epoch_dqn': n_epoch_dqn, \n",
    "                                                                           'beam_width': beam_width, \n",
    "                                                                           'i_step': i_step, \n",
    "                                                                           'flag_found_destination': flag_found_destination, \n",
    "                                                                           'mlp_losses': mlp_losses[-1], \n",
    "                                                                           'dqn_losses': dqn_losses[-1],\n",
    "                                                                           'min_diff': min_diff,\n",
    "                                                                           'max_diff': max_diff,\n",
    "                                                                           'mean_diff': mean_diff,\n",
    "                                                                           'std_diff': std_diff,\n",
    "                                                                           'num_elements_less_than_minus_05': num_elements_less_than_minus_05,\n",
    "                                                                           'num_elements_larger_than_05': num_elements_larger_than_05,\n",
    "                                                                           'percentage_wrong_predictions': percentage_wrong_predictions\n",
    "                                                                           })\n",
    "                                            summary_df = pd.concat([summary_df, summary_df_cur])\n",
    "                                            summary_df.to_csv('models/summary_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1982195323.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Добавь нормальное тестирование.\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Добавь модель Кирилла\n",
    "Сделай пуш\n",
    "Поставь обучение на васт эй ай\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_permutations_length</th>\n",
       "      <th>n_rnd_walks_sup_mode</th>\n",
       "      <th>n_rnd_walks_rl_mode</th>\n",
       "      <th>anchor</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>list_layers_sizes</th>\n",
       "      <th>lr_supervised</th>\n",
       "      <th>lr_rl</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>n_epoch_dqn</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_found_destination</th>\n",
       "      <th>mlp_losses</th>\n",
       "      <th>dqn_losses</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>num_elements_less_than_minus_05</th>\n",
       "      <th>num_elements_larger_than_05</th>\n",
       "      <th>percentage_wrong_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>10.064562</td>\n",
       "      <td>0.047639</td>\n",
       "      <td>-3.053122</td>\n",
       "      <td>2.960304</td>\n",
       "      <td>0.117633</td>\n",
       "      <td>0.697093</td>\n",
       "      <td>69640</td>\n",
       "      <td>110067</td>\n",
       "      <td>0.500227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>24.519262</td>\n",
       "      <td>0.117222</td>\n",
       "      <td>-4.568487</td>\n",
       "      <td>3.968890</td>\n",
       "      <td>-0.026837</td>\n",
       "      <td>0.956822</td>\n",
       "      <td>303835</td>\n",
       "      <td>300407</td>\n",
       "      <td>0.610345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_permutations_length  n_rnd_walks_sup_mode  n_rnd_walks_rl_mode  anchor  \\\n",
       "0                      9                 10000                10000       0   \n",
       "0                     10                 10000                10000       0   \n",
       "\n",
       "   batch_size  list_layers_sizes  lr_supervised  lr_rl  n_epoch  n_epoch_dqn  \\\n",
       "0        1024               4096          0.001  0.001       10           10   \n",
       "0        1024               4096          0.001  0.001       10           10   \n",
       "\n",
       "   ...  flag_found_destination  mlp_losses  dqn_losses  min_diff  max_diff  \\\n",
       "0  ...                    True   10.064562    0.047639 -3.053122  2.960304   \n",
       "0  ...                    True   24.519262    0.117222 -4.568487  3.968890   \n",
       "\n",
       "   mean_diff  std_diff  num_elements_less_than_minus_05  \\\n",
       "0   0.117633  0.697093                            69640   \n",
       "0  -0.026837  0.956822                           303835   \n",
       "\n",
       "   num_elements_larger_than_05  percentage_wrong_predictions  \n",
       "0                       110067                      0.500227  \n",
       "0                       300407                      0.610345  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36288, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.X_anchor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362880"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def factorial(n):\n",
    "    \"\"\"Calculate the factorial of a non-negative integer n.\"\"\"\n",
    "    if n < 0:\n",
    "        raise ValueError(\"Factorial is not defined for negative numbers\")\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    result = 1\n",
    "    for i in range(2, n + 1):\n",
    "        result *= i\n",
    "    return result\n",
    "\n",
    "factorial(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18000/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362880\n",
      "X.shape: torch.Size([362880, 9])\n",
      "y.shape: torch.Size([362880])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2,  ..., 6, 7, 8],\n",
       "         [1, 2, 3,  ..., 7, 8, 0],\n",
       "         [8, 0, 1,  ..., 5, 6, 7],\n",
       "         ...,\n",
       "         [0, 8, 7,  ..., 3, 2, 1],\n",
       "         [2, 1, 0,  ..., 5, 4, 3],\n",
       "         [1, 0, 8,  ..., 4, 3, 2]], device='cuda:0'),\n",
       " tensor([ 0,  1,  1,  ..., 35, 35, 36], device='cuda:0'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.generate_training_data_anchor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distribution of the torch vector y_valid\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(diff, bins=30, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of y_valid')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

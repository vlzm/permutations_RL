{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from src.app import PermutationSolver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "config = {\n",
    "                'n_permutations_length': n,\n",
    "                \n",
    "                # Random walks params\n",
    "                'random_walks_type': 'non-backtracking-beam',\n",
    "                'n_random_walk_length': int(n * (n-1) / 2),\n",
    "                'n_random_walks_to_generate': 1000,\n",
    "                'n_random_walks_steps_back_to_ban': 8,\n",
    "                \n",
    "                # Neural Net params\n",
    "                'model_type': 'MLP',\n",
    "                'list_layers_sizes': [4096],\n",
    "                'n_epochs': 100,\n",
    "                'batch_size': 1024,\n",
    "                'lr_supervised': 1e-3,\n",
    "                \n",
    "                # DQN training\n",
    "                'n_epochs_dqn': 5000,\n",
    "                'flag_dqn_round': False,\n",
    "                'n_random_walks_to_generate_dqn': 1000,\n",
    "                'verbose_loc': 50,\n",
    "                'lr_rl': 1e-3,\n",
    "                \n",
    "                # Beam search\n",
    "                'beam_search_torch': True,\n",
    "                'beam_search_Fironov': False,\n",
    "                'beam_width': 1,\n",
    "                'n_steps_limit': 4 * n**2,\n",
    "                'alpha_previous_cost_accumulation': 0,\n",
    "                'beam_search_models_or_heuristics': 'model_torch',\n",
    "                'ban_p0_p1_transposition_if_p0_lt_p1_ie_already_sorted': False,\n",
    "                'n_beam_search_steps_back_to_ban': 32,\n",
    "                \n",
    "                # What to solve\n",
    "                'solve_random_or_longest_state': 'solve_LRX_longest',\n",
    "                'verbose': 100\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_epoch \u001b[38;5;129;01min\u001b[39;00m n_epoch_list:\n\u001b[0;32m     45\u001b[0m     solver\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[1;32m---> 46\u001b[0m     mlp_losses \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw_anchor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# save mlp_model\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(solver\u001b[38;5;241m.\u001b[39mmlp_model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/mlp_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_permutations_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlist_layers_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlp_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zamko\\Documents\\permutations_RL\\src\\app.py:245\u001b[0m, in \u001b[0;36mPermutationSolver.train_mlp\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train MLP model\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_mlp_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_exp_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unique_log_dir()\n",
      "File \u001b[1;32mc:\\Users\\zamko\\Documents\\permutations_RL\\src\\app.py:121\u001b[0m, in \u001b[0;36mPermutationSolver.setup_mlp_model\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    118\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_permutations_length\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_generators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_rw_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_anchor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_anchor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_training_data_anchor(mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquadruples\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\zamko\\Documents\\permutations_RL\\src\\app.py:113\u001b[0m, in \u001b[0;36mPermutationSolver._init_rw_generators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_generators \u001b[38;5;241m=\u001b[39m [L, R, X]\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Precompute neighbors tensor if needed by trainer\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Here, tensor_generators is simply passed along to DQNTrainer\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_generators \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_generators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_destination \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(n, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n",
      "File \u001b[1;32mc:\\Users\\zamko\\Documents\\permutations_RL\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gpu_num = 1\n",
    "\n",
    "n_perm_list = [12]\n",
    "n_epoch_list = [100]\n",
    "n_epoch_dqn_list = [100]\n",
    "mlp_batch_size_list = [2**10]\n",
    "dqn_batch_size_list = [2**16]\n",
    "lr_supervised_list = [1e-3]\n",
    "lr_rl_list = [1e-2]\n",
    "n_rnd_walks_sup = [10_000]\n",
    "n_rnd_walks_rl = [10_000]\n",
    "anchor_list = [0]\n",
    "beam_width_list = [2**0]\n",
    "list_layers_sizes = [2**12]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for n_permutations_length in n_perm_list:\n",
    "\n",
    "    n = n_permutations_length\n",
    "    config['n_permutations_length'] = n\n",
    "    config['n_random_walk_length'] = int(n * (n-1) / 2)\n",
    "    \n",
    "    config['mode'] = 'single_hard_hinge'\n",
    "    config['w_hinge'] = 1.0\n",
    "    \n",
    "    for anchor_mode in anchor_list:\n",
    "        config['w_anchor'] = anchor_mode\n",
    "        for n_rnd_walks_sup_mode in n_rnd_walks_sup:\n",
    "            config['n_random_walks_to_generate'] = n_rnd_walks_sup_mode\n",
    "            for n_rnd_walks_rl_mode in n_rnd_walks_rl:\n",
    "                config['n_random_walks_to_generate_dqn'] = n_rnd_walks_rl_mode\n",
    "                solver = PermutationSolver(config, gpu_id=gpu_num)\n",
    "                solver.config['n_permutations_length'] = n_permutations_length\n",
    "                for list_layers_size in list_layers_sizes:\n",
    "                    solver.config['list_layers_sizes'] = [list_layers_size]\n",
    "                    print(list_layers_size)\n",
    "                    for lr in lr_supervised_list:\n",
    "                        solver.config['lr_supervised'] = lr\n",
    "                        for lr_rl in lr_rl_list:\n",
    "                            solver.config['lr_rl'] = lr_rl\n",
    "                            for mlp_batch_size in mlp_batch_size_list:\n",
    "                                solver.config['mlp_batch_size'] = mlp_batch_size\n",
    "                                for n_epoch in n_epoch_list:\n",
    "                                    solver.config['n_epochs'] = n_epoch\n",
    "                                    mlp_losses = solver.train_mlp(mode = config['w_anchor'])\n",
    "                                    # save mlp_model\n",
    "                                    torch.save(solver.mlp_model.state_dict(), f'models/mlp_model_{n_permutations_length}_{n_epoch}_{list_layers_size}_{lr}_{mlp_batch_size}.pth')\n",
    "                                    for n_epoch_dqn in n_epoch_dqn_list:\n",
    "                                        for dqn_batch_size in dqn_batch_size_list:\n",
    "                                            solver.config['dqn_batch_size'] = dqn_batch_size\n",
    "                                            solver.config['n_epochs_dqn'] = n_epoch_dqn\n",
    "                                            dqn_losses = solver.train_dqn()\n",
    "                                            # save dqn_model\n",
    "                                            torch.save(solver.dqn_model.state_dict(), f'models/dqn_model_{n_permutations_length}_{n_epoch_dqn}_{list_layers_size}_{lr}_{dqn_batch_size}.pth')\n",
    "                                            for beam_width in beam_width_list:\n",
    "                                                solver.config['beam_width'] = beam_width\n",
    "                                                i_step, flag_found_destination, path = solver.test_beam_search()\n",
    "                \n",
    "                                                # calculate min and max of difference between solver.y_anchor and y_valid\n",
    "                                                # y_valid = solver.dqn_model(solver.X_anchor)\n",
    "                                                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                                                solver.dqn_trainer.model.eval()               # set to eval mode\n",
    "                                                y_parts = []\n",
    "                                                n_samples = len(solver.X_anchor)\n",
    "                                                with torch.no_grad():                 # <— no grad tracking\n",
    "                                                    for start in range(0, n_samples, mlp_batch_size):\n",
    "                                                        end = start + mlp_batch_size\n",
    "                                                        X_batch = solver.X_anchor[start:end].to(device)\n",
    "                                                        y_batch = solver.dqn_trainer.model(X_batch)\n",
    "                                                        y_parts.append(y_batch.cpu()) # move back to CPU\n",
    "                                                        # explicitly free GPU memory\n",
    "                                                        del X_batch, y_batch\n",
    "                                                        torch.cuda.empty_cache()\n",
    "                                                \n",
    "                                                y_valid = torch.cat(y_parts, dim=0)\n",
    "                                                \n",
    "                                                diff = solver.y_anchor.cpu().detach().numpy() - y_valid.cpu().detach().numpy().reshape(1, -1)[0]\n",
    "                                                min_diff = diff.min()\n",
    "                                                max_diff = diff.max()\n",
    "                                                std_diff = diff.std()\n",
    "                                                mean_diff = diff.mean()\n",
    "                                                num_elements_less_than_minus_05 = (diff < -0.5).sum()\n",
    "                                                num_elements_larger_than_05 = (diff > 0.5).sum()\n",
    "                                                wrong_predictions = num_elements_less_than_minus_05 + num_elements_larger_than_05\n",
    "                                                percentage_wrong_predictions = wrong_predictions / len(diff)\n",
    "                \n",
    "                                                # save summary_df\n",
    "                                                summary_df_cur = pd.DataFrame({'n_permutations_length': n_permutations_length,\n",
    "                                                                            'n_rnd_walks_sup_mode': n_rnd_walks_sup_mode,\n",
    "                                                                            'n_rnd_walks_rl_mode': n_rnd_walks_rl_mode,\n",
    "                                                                            'anchor':anchor_mode,\n",
    "                                                                            'mlp_batch_size':mlp_batch_size,\n",
    "                                                                            'dqn_batch_size':dqn_batch_size,\n",
    "                                                                            'list_layers_sizes': [list_layers_size], \n",
    "                                                                            'lr_supervised': lr,\n",
    "                                                                            'lr_rl': lr_rl, \n",
    "                                                                            'n_epoch': n_epoch, \n",
    "                                                                            'n_epoch_dqn': n_epoch_dqn, \n",
    "                                                                            'beam_width': beam_width, \n",
    "                                                                            'i_step': i_step, \n",
    "                                                                            'flag_found_destination': flag_found_destination, \n",
    "                                                                            'mlp_losses': mlp_losses[-1], \n",
    "                                                                            'dqn_losses': dqn_losses[-1],\n",
    "                                                                            'min_diff': min_diff,\n",
    "                                                                            'max_diff': max_diff,\n",
    "                                                                            'mean_diff': mean_diff,\n",
    "                                                                            'std_diff': std_diff,\n",
    "                                                                            'num_elements_less_than_minus_05': num_elements_less_than_minus_05,\n",
    "                                                                            'num_elements_larger_than_05': num_elements_larger_than_05,\n",
    "                                                                            'percentage_wrong_predictions': percentage_wrong_predictions\n",
    "                                                                            })\n",
    "                                                summary_df = pd.concat([summary_df, summary_df_cur])\n",
    "                                                summary_df.to_csv('models/summary_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.484506\n",
       "Name: dqn_losses, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df['dqn_losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1982195323.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Добавь нормальное тестирование.\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Добавь модель Кирилла\n",
    "Сделай пуш\n",
    "Поставь обучение на васт эй ай\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_permutations_length</th>\n",
       "      <th>n_rnd_walks_sup_mode</th>\n",
       "      <th>n_rnd_walks_rl_mode</th>\n",
       "      <th>anchor</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>list_layers_sizes</th>\n",
       "      <th>lr_supervised</th>\n",
       "      <th>lr_rl</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>n_epoch_dqn</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_found_destination</th>\n",
       "      <th>mlp_losses</th>\n",
       "      <th>dqn_losses</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>num_elements_less_than_minus_05</th>\n",
       "      <th>num_elements_larger_than_05</th>\n",
       "      <th>percentage_wrong_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>10.064562</td>\n",
       "      <td>0.047639</td>\n",
       "      <td>-3.053122</td>\n",
       "      <td>2.960304</td>\n",
       "      <td>0.117633</td>\n",
       "      <td>0.697093</td>\n",
       "      <td>69640</td>\n",
       "      <td>110067</td>\n",
       "      <td>0.500227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>24.519262</td>\n",
       "      <td>0.117222</td>\n",
       "      <td>-4.568487</td>\n",
       "      <td>3.968890</td>\n",
       "      <td>-0.026837</td>\n",
       "      <td>0.956822</td>\n",
       "      <td>303835</td>\n",
       "      <td>300407</td>\n",
       "      <td>0.610345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_permutations_length  n_rnd_walks_sup_mode  n_rnd_walks_rl_mode  anchor  \\\n",
       "0                      9                 10000                10000       0   \n",
       "0                     10                 10000                10000       0   \n",
       "\n",
       "   batch_size  list_layers_sizes  lr_supervised  lr_rl  n_epoch  n_epoch_dqn  \\\n",
       "0        1024               4096          0.001  0.001       10           10   \n",
       "0        1024               4096          0.001  0.001       10           10   \n",
       "\n",
       "   ...  flag_found_destination  mlp_losses  dqn_losses  min_diff  max_diff  \\\n",
       "0  ...                    True   10.064562    0.047639 -3.053122  2.960304   \n",
       "0  ...                    True   24.519262    0.117222 -4.568487  3.968890   \n",
       "\n",
       "   mean_diff  std_diff  num_elements_less_than_minus_05  \\\n",
       "0   0.117633  0.697093                            69640   \n",
       "0  -0.026837  0.956822                           303835   \n",
       "\n",
       "   num_elements_larger_than_05  percentage_wrong_predictions  \n",
       "0                       110067                      0.500227  \n",
       "0                       300407                      0.610345  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36288, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.X_anchor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362880"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def factorial(n):\n",
    "    \"\"\"Calculate the factorial of a non-negative integer n.\"\"\"\n",
    "    if n < 0:\n",
    "        raise ValueError(\"Factorial is not defined for negative numbers\")\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    result = 1\n",
    "    for i in range(2, n + 1):\n",
    "        result *= i\n",
    "    return result\n",
    "\n",
    "factorial(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18000/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362880\n",
      "X.shape: torch.Size([362880, 9])\n",
      "y.shape: torch.Size([362880])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2,  ..., 6, 7, 8],\n",
       "         [1, 2, 3,  ..., 7, 8, 0],\n",
       "         [8, 0, 1,  ..., 5, 6, 7],\n",
       "         ...,\n",
       "         [0, 8, 7,  ..., 3, 2, 1],\n",
       "         [2, 1, 0,  ..., 5, 4, 3],\n",
       "         [1, 0, 8,  ..., 4, 3, 2]], device='cuda:0'),\n",
       " tensor([ 0,  1,  1,  ..., 35, 35, 36], device='cuda:0'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.generate_training_data_anchor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distribution of the torch vector y_valid\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(diff, bins=30, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of y_valid')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

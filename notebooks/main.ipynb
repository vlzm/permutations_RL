{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from src.app import PermutationSolver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "config = {\n",
    "            'n_permutations_length': n,\n",
    "            \n",
    "            # Random walks params\n",
    "            'random_walks_type': 'non-backtracking-beam',\n",
    "            'n_random_walk_length': int(n * (n-1) / 2),\n",
    "            'n_random_walks_to_generate': 10000,\n",
    "            'n_random_walks_steps_back_to_ban': 8,\n",
    "            \n",
    "            # Neural Net params\n",
    "            'model_type': 'MLP',\n",
    "            'list_layers_sizes': [2**9],\n",
    "            'n_epochs': 30,\n",
    "            'batch_size': 1024,\n",
    "            'lr': 0.001,\n",
    "            \n",
    "            # DQN training\n",
    "            'n_epochs_dqn': 300,\n",
    "            'flag_dqn_round': False,\n",
    "            'n_random_walks_to_generate_dqn': 1000,\n",
    "            'verbose_loc': 5,\n",
    "            'lr_dqn': 0.0005,\n",
    "            \n",
    "            # Beam search\n",
    "            'beam_search_torch': True,\n",
    "            'beam_search_Fironov': False,\n",
    "            'beam_width': 1,\n",
    "            'n_steps_limit': 4 * n**2,\n",
    "            'alpha_previous_cost_accumulation': 0,\n",
    "            'beam_search_models_or_heuristics': 'model_torch',\n",
    "            'ban_p0_p1_transposition_if_p0_lt_p1_ie_already_sorted': False,\n",
    "            'n_beam_search_steps_back_to_ban': 32,\n",
    "            \n",
    "            # What to solve\n",
    "            'solve_random_or_longest_state': 'solve_LRX_longest',\n",
    "            'verbose': 100\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perm_list = [n]\n",
    "n_epoch_list = [30]\n",
    "n_epoch_dqn_list = [100]\n",
    "batch_size_list = [2**10]\n",
    "lr_list = [0.001]\n",
    "beam_width_list = [2**0]\n",
    "list_layers_sizes = [[2*9]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['mode'] = 'single_hard_hinge'\n",
    "config['w_anchor'] = 0.0\n",
    "config['w_hinge'] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP:  33%|███▎      | 10/30 [00:04<00:09,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 2.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP:  67%|██████▋   | 20/30 [00:09<00:04,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 1.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MLP: 100%|██████████| 30/30 [00:14<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 2.1955\n",
      "40320\n",
      "X.shape: torch.Size([40320, 8])\n",
      "y.shape: torch.Size([40320])\n",
      "Starting DQN training for 100 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:   2%|▏         | 2/100 [00:00<00:11,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Loss: 0.8001 | Hinge: 0.7727 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.03s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:   7%|▋         | 7/100 [00:00<00:09,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 | Loss: 0.4822 | Hinge: 0.4482 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  12%|█▏        | 12/100 [00:01<00:09,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 | Loss: 0.3849 | Hinge: 0.4041 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  17%|█▋        | 17/100 [00:01<00:09,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15 | Loss: 0.3410 | Hinge: 0.2612 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  22%|██▏       | 22/100 [00:02<00:08,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 | Loss: 0.3118 | Hinge: 0.3009 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  27%|██▋       | 27/100 [00:03<00:08,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  25 | Loss: 0.2995 | Hinge: 0.3039 | Anchor: 0.0000 | Times - RW: 0.06s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  32%|███▏      | 32/100 [00:03<00:08,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30 | Loss: 0.2817 | Hinge: 0.2806 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  37%|███▋      | 37/100 [00:04<00:06,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  35 | Loss: 0.2669 | Hinge: 0.2958 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  42%|████▏     | 42/100 [00:04<00:06,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 | Loss: 0.2642 | Hinge: 0.2851 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  47%|████▋     | 47/100 [00:05<00:05,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  45 | Loss: 0.2578 | Hinge: 0.2677 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  53%|█████▎    | 53/100 [00:05<00:04,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 | Loss: 0.2542 | Hinge: 0.2128 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  57%|█████▋    | 57/100 [00:06<00:04,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  55 | Loss: 0.2470 | Hinge: 0.2485 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  63%|██████▎   | 63/100 [00:06<00:03,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60 | Loss: 0.2482 | Hinge: 0.2140 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  67%|██████▋   | 67/100 [00:07<00:03,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  65 | Loss: 0.2374 | Hinge: 0.2334 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  72%|███████▏  | 72/100 [00:07<00:03,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70 | Loss: 0.2365 | Hinge: 0.2577 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  77%|███████▋  | 77/100 [00:08<00:02,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  75 | Loss: 0.2354 | Hinge: 0.2074 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  82%|████████▏ | 82/100 [00:09<00:01,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80 | Loss: 0.2296 | Hinge: 0.2397 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  87%|████████▋ | 87/100 [00:09<00:01,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  85 | Loss: 0.2335 | Hinge: 0.2354 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  92%|█████████▏| 92/100 [00:10<00:00,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90 | Loss: 0.2224 | Hinge: 0.1942 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN:  97%|█████████▋| 97/100 [00:10<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  95 | Loss: 0.2305 | Hinge: 0.2324 | Anchor: 0.0000 | Times - RW: 0.05s, Bellman: 0.01s, Train: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DQN: 100%|██████████| 100/100 [00:11<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 11.0s\n",
      "{'n_permutations_length': 8, 'random_walks_type': 'non-backtracking-beam', 'n_random_walk_length': 28, 'n_random_walks_to_generate': 10000, 'n_random_walks_steps_back_to_ban': 8, 'model_type': 'MLP', 'list_layers_sizes': [18], 'n_epochs': 30, 'batch_size': 1024, 'lr': 0.001, 'n_epochs_dqn': 100, 'flag_dqn_round': False, 'n_random_walks_to_generate_dqn': 1000, 'verbose_loc': 5, 'lr_dqn': 0.001, 'beam_search_torch': True, 'beam_search_Fironov': False, 'beam_width': 1, 'n_steps_limit': 256, 'alpha_previous_cost_accumulation': 0, 'beam_search_models_or_heuristics': 'model_torch', 'ban_p0_p1_transposition_if_p0_lt_p1_ie_already_sorted': False, 'n_beam_search_steps_back_to_ban': 32, 'solve_random_or_longest_state': 'solve_LRX_longest', 'verbose': 100, 'mode': 'single_hard_hinge', 'w_anchor': 0.0, 'w_hinge': 1.0}\n",
      "\n",
      "beam_width: 1\n",
      "n= 8\n",
      "n(n-1)/2= 28\n",
      "Found Path Length: 28 flag_found_destination: True\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for n_permutations_length in n_perm_list:\n",
    "    solver = PermutationSolver(config)\n",
    "    solver.config['n_permutations_length'] = n_permutations_length\n",
    "    for list_layers_size in list_layers_sizes:\n",
    "        solver.config['list_layers_sizes'] = list_layers_size\n",
    "        for lr in lr_list:\n",
    "            solver.config['lr_dqn'] = lr\n",
    "            for batch_size in batch_size_list:\n",
    "                solver.config['batch_size'] = batch_size\n",
    "                for n_epoch in n_epoch_list:\n",
    "                    solver.config['n_epochs'] = n_epoch\n",
    "                    mlp_losses = solver.train_mlp()\n",
    "                    # save mlp_model\n",
    "                    torch.save(solver.mlp_model.state_dict(), f'models/mlp_model_{n_permutations_length}_{n_epoch}_{list_layers_sizes[0]}_{lr}_{batch_size}.pth')\n",
    "                    for n_epoch_dqn in n_epoch_dqn_list:\n",
    "                        solver.config['n_epochs_dqn'] = n_epoch_dqn\n",
    "                        dqn_losses = solver.train_dqn()\n",
    "                        # save dqn_model\n",
    "                        torch.save(solver.dqn_model.state_dict(), f'models/dqn_model_{n_permutations_length}_{n_epoch_dqn}_{list_layers_sizes[0]}_{lr}_{batch_size}.pth')\n",
    "                        for beam_width in beam_width_list:\n",
    "                            solver.config['beam_width'] = beam_width\n",
    "                            i_step, flag_found_destination, path = solver.test_beam_search()\n",
    "                            # save summary_df\n",
    "                            summary_df = pd.concat([summary_df, pd.DataFrame({'n_permutations_length': n_permutations_length, 'list_layers_sizes': list_layers_sizes, 'lr': lr, 'n_epoch': n_epoch, 'n_epoch_dqn': n_epoch_dqn, 'beam_width': beam_width, 'i_step': i_step, 'flag_found_destination': flag_found_destination, 'mlp_losses': mlp_losses[-1], 'dqn_losses': dqn_losses[-1]})])\n",
    "                            summary_df.to_csv('models/summary_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 0, 7, 6, 5, 4, 3, 2], device='cuda:0'),\n",
       " tensor([0, 1, 7, 6, 5, 4, 3, 2]),\n",
       " tensor([1, 7, 6, 5, 4, 3, 2, 0]),\n",
       " tensor([7, 1, 6, 5, 4, 3, 2, 0]),\n",
       " tensor([0, 7, 1, 6, 5, 4, 3, 2]),\n",
       " tensor([7, 0, 1, 6, 5, 4, 3, 2]),\n",
       " tensor([0, 1, 6, 5, 4, 3, 2, 7]),\n",
       " tensor([1, 6, 5, 4, 3, 2, 7, 0]),\n",
       " tensor([6, 5, 4, 3, 2, 7, 0, 1]),\n",
       " tensor([5, 4, 3, 2, 7, 0, 1, 6]),\n",
       " tensor([4, 5, 3, 2, 7, 0, 1, 6]),\n",
       " tensor([5, 3, 2, 7, 0, 1, 6, 4]),\n",
       " tensor([3, 5, 2, 7, 0, 1, 6, 4]),\n",
       " tensor([4, 3, 5, 2, 7, 0, 1, 6]),\n",
       " tensor([3, 4, 5, 2, 7, 0, 1, 6]),\n",
       " tensor([6, 3, 4, 5, 2, 7, 0, 1]),\n",
       " tensor([3, 6, 4, 5, 2, 7, 0, 1]),\n",
       " tensor([6, 4, 5, 2, 7, 0, 1, 3]),\n",
       " tensor([4, 6, 5, 2, 7, 0, 1, 3]),\n",
       " tensor([6, 5, 2, 7, 0, 1, 3, 4]),\n",
       " tensor([5, 6, 2, 7, 0, 1, 3, 4]),\n",
       " tensor([6, 2, 7, 0, 1, 3, 4, 5]),\n",
       " tensor([2, 7, 0, 1, 3, 4, 5, 6]),\n",
       " tensor([7, 2, 0, 1, 3, 4, 5, 6]),\n",
       " tensor([2, 0, 1, 3, 4, 5, 6, 7]),\n",
       " tensor([0, 2, 1, 3, 4, 5, 6, 7]),\n",
       " tensor([2, 1, 3, 4, 5, 6, 7, 0]),\n",
       " tensor([1, 2, 3, 4, 5, 6, 7, 0]),\n",
       " tensor([0, 1, 2, 3, 4, 5, 6, 7])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9aea234ff040febc85090699cc0a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Frame', max=28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31080b9a012347828504dd9cadf6825c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "def visualize_tensor_sequence_notebook(tensor_list):\n",
    "    \"\"\"\n",
    "    Интерактивная визуализация в Jupyter Notebook в виде линии шариков:\n",
    "    - Использует ipywidgets.IntSlider и перерисовывает график в Output\n",
    "    - tensor_list: список torch.Tensor размера (N, M)\n",
    "    \"\"\"\n",
    "    M = tensor_list[0].shape[0]\n",
    "    N = len(tensor_list)\n",
    "    # позиции на линии: равномерные точки по оси X\n",
    "    xs = np.arange(M)\n",
    "    ys = np.zeros(M)\n",
    "\n",
    "    # слайдер и область вывода\n",
    "    slider = widgets.IntSlider(value=0, min=0, max=N-1, step=1, description='Frame')\n",
    "    out = widgets.Output()\n",
    "    \n",
    "    def plot_frame(idx):\n",
    "        vals = tensor_list[idx]\n",
    "        arr = vals.cpu().numpy().astype(float)\n",
    "        norm = arr / arr.max()\n",
    "        hsv = np.stack([np.zeros_like(norm), norm, np.ones_like(norm)], axis=1)\n",
    "        rgb = hsv_to_rgb(hsv)\n",
    "        \n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            fig, ax = plt.subplots(figsize=(8,2))\n",
    "            ax.set_aspect('equal')\n",
    "            ax.axis('off')\n",
    "            # рисуем шарики вдоль линии\n",
    "            scatter = ax.scatter(xs, ys, s=800, color=rgb)\n",
    "            # цифры внутри шариков\n",
    "            for x, y, v in zip(xs, ys, vals):\n",
    "                ax.text(x, y, str(v.item()), ha='center', va='center', fontsize=12, color='black')\n",
    "            # статус 'start' и 'done'\n",
    "            status = 'start' if idx == 0 else ('done' if idx == N-1 else '')\n",
    "            ax.text(M/2 - 0.5, 0.3, status, ha='center', va='bottom', fontsize=16)\n",
    "            # установка границ\n",
    "            ax.set_xlim(-1, M)\n",
    "            ax.set_ylim(-1, 1)\n",
    "            plt.show()\n",
    "\n",
    "    # подписка на изменение слайдера\n",
    "    slider.observe(lambda change: plot_frame(change['new']), names='value')\n",
    "    display(slider, out)\n",
    "    # отрисовка начального кадра\n",
    "    plot_frame(0)\n",
    "\n",
    "\n",
    "visualize_tensor_sequence_notebook(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
